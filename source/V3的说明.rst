.. Kenneth Lee 版权所有 2025

:Authors: Kenneth Lee
:Version: 3.0

V3的说明
********

如果读者看到这一段文字，说明您看的是本文3.0以上的版本。

我决定要升级这个版本的主要原因是这几年大语言模型（LLM）有了很大的发展，为我们
解释《道德经》提供了更多的概念工具，让我们可以更容易沟通《道德经》里面描述的概
念，所以我希望引入这些概念工具来帮助读者更好理解《道德经》想要表达的东西。

我不希望上面这个表述让不是LLM领域的读者感到焦虑，觉得这个版本会让你看不懂。实
际上我没有打算改变本书的整体描述内容。你可以认为这个版本我只是增加了给不是做
LLM的读者一些科普，让你可以更好理解大语言模型是怎么工作的。在你理解这些细节后，
你就会形成新的概念，我们就可以用这些概念更好地认识《道德经》所表达的内容了。

这个道理就好像你没有见过狗，也没有见过猫。我给你形容狗，半天你也不明白。但如果
你见过猫，我用猫去类比狗，你就会容易很多。这里的“猫”，就是我们在沟通“狗”的时候
用的“概念工具”。

所以，我们也不是像某些喜欢附会的人那样，说什么“老子在两千多年前就已经参透LLM了”。
这样看问题说明他们连“名”的基本认识都没有，就更谈不上什么“理解《道德经》”了。
LLM的概念可以用于理解《道德经》，是因为它们研究的是同一个领域：语言的特征。但
老子研究语言的特征是为了解决高层判断问题，而LLM研究语言的特征是为了解决知识的
抽象问题。

那么我们现在就来说说LLM的“训练”。我们很多人对LLM的具象认识就是使用ChatGPT，
DeepSeek这些工具的认知：聊天机器人。这个东西很像一个人，你问它问题，它回答你问
题。

过去计算机模拟的聊天机器人大部分都是基于“逻辑思维”的。什么意思呢？就是你输入一
句话，计算机必须通过一组逻辑判断，根据这些逻辑判断固定返回什么回答。

todo：补一幅图。

这种聊天机器人最大的问题是变化有限，因为逻辑判断的每个分支，都需要人脑去写程序
设计的，人脑发明逻辑的速度是有限的，所以逻辑思维制造的计算机只适合固定的逻辑。
比如在数据库中查找一个信息，或者用实现成计算器，只有有限的输入，使用固定的计算
过程完成计算。

todo：后面的慢慢再写。
